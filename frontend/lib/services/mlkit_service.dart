import 'dart:async';
import 'dart:io';
import 'dart:math' as math;
import 'dart:ui' as ui;

import 'package:camera/camera.dart';
import 'package:flutter/foundation.dart';
import 'package:google_mlkit_pose_detection/google_mlkit_pose_detection.dart';

/// ML Kit Pose Detection æœåŠ¡
///
/// ä½¿ç”¨ google_ml_kit_pose_detection æ’ä»¶
/// âš ï¸ ç¦æ­¢ä½¿ç”¨åŸç”Ÿ MediaPipe C++ æ¡¥æ¥
class MLKitPoseService {
  PoseDetector? _poseDetector;
  bool _isProcessing = false;
  final StreamController<List<Pose>> _poseStreamController = StreamController.broadcast();

  Stream<List<Pose>> get poseStream => _poseStreamController.stream;
  bool get isProcessing => _isProcessing;

  /// åˆå§‹åŒ– Pose Detector
  ///
  /// ä½¿ç”¨ Lite æ¨¡å‹ä»¥è·å¾—æœ€ä½³æ€§èƒ½
  Future<void> initialize() async {
    if (_poseDetector != null) {
      debugPrint('MLKitPoseService: Already initialized');
      return;
    }

    try {
      // æ³¨æ„ï¼šæƒé™è¯·æ±‚å·²ç§»è‡³ HomeScreen Switch ä¸­ç»Ÿä¸€å¤„ç†
      // ä¸å†åœ¨æ­¤å¤„è¯·æ±‚æƒé™ï¼Œé¿å…é‡å¤è¯·æ±‚å’Œæƒé™ç«äº‰

      // åˆ›å»º Pose Detector
      // ä½¿ç”¨ Base æ¨¡å‹ï¼ˆæœ€å¿«ï¼‰å’Œ stream æ¨¡å¼
      final options = PoseDetectorOptions(
        model: PoseDetectionModel.base,
        mode: PoseDetectionMode.stream,
      );

      _poseDetector = PoseDetector(options: options);

      debugPrint('MLKitPoseService: Initialized with Base model + stream mode');
    } catch (e) {
      debugPrint('MLKitPoseService: Initialization failed - $e');
      rethrow;
    }
  }

  /// å¤„ç†ç›¸æœºå›¾åƒå¸§å¹¶æ£€æµ‹å§¿æ€
  ///
  /// æ³¨æ„ï¼šä¸å†ä½¿ç”¨ compute() é¿å… BackgroundIsolateBinaryMessenger é”™è¯¯
  /// ML Kit Pose Detection å·²åœ¨åŸç”Ÿå±‚ä¼˜åŒ–ï¼Œä¸ä¼šé˜»å¡ UI çº¿ç¨‹
  /// é…åˆ FrameThrottlerï¼ˆ10 FPSï¼‰ä½¿ç”¨ï¼Œæ€§èƒ½è¡¨ç°è‰¯å¥½
  Future<void> processCameraImage(CameraImage image, CameraDescription? cameraDescription) async {
    if (_poseDetector == null) {
      debugPrint('MLKitPoseService: Not initialized');
      return;
    }

    if (_isProcessing) {
      // è·³è¿‡ï¼Œä¸Šä¸€å¸§è¿˜åœ¨å¤„ç†
      return;
    }

    _isProcessing = true;

    try {
      // è½¬æ¢ CameraImage ä¸º InputImageï¼ˆä¼ é€’ç›¸æœºæè¿°ç”¨äºæ—‹è½¬è®¡ç®—ï¼‰
      final inputImage = ImageUtils.toInputImage(image, cameraDescription);

      // ç›´æ¥è°ƒç”¨ ML Kit è¿›è¡Œå§¿æ€æ£€æµ‹
      // ä¸å†ä½¿ç”¨ compute() é¿å… BackgroundIsolateBinaryMessenger é”™è¯¯
      final poses = await _poseDetector!.processImage(inputImage);

      // æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼ˆæ¯ 30 å¸§æ‰“å°ä¸€æ¬¡ï¼‰
      final frameNumber = DateTime.now().millisecondsSinceEpoch ~/ 100;
      if (frameNumber % 30 == 0) {
        debugPrint('ğŸ“¸ Frame: ${image.width}x${image.height}, '
            'format: raw=${image.format.raw}, '
            'rotation: ${inputImage.metadata?.rotation}, '
            'poses: ${poses.length}, '
            'landmarks: ${poses.isNotEmpty ? poses.first.landmarks.length : 0}');

        // æ‰“å° nose åæ ‡ï¼ˆå¦‚æœæ£€æµ‹åˆ°ï¼‰
        if (poses.isNotEmpty) {
          final pose = poses.first;
          final nose = pose.landmarks[PoseLandmarkType.nose];
          if (nose != null) {
            debugPrint('ğŸ‘ƒ Nose: x=${nose.x.toStringAsFixed(3)}, '
                'y=${nose.y.toStringAsFixed(3)}, '
                'likelihood=${nose.likelihood.toStringAsFixed(3)}');
          } else {
            debugPrint('âš ï¸  No nose landmark detected');
          }
        }
      }

      if (poses.isNotEmpty) {
        _poseStreamController.add(poses);
      }
    } catch (e) {
      debugPrint('MLKitPoseService: Detection failed - $e');
    } finally {
      _isProcessing = false;
    }
  }

  /// é‡Šæ”¾èµ„æº
  Future<void> dispose() async {
    await _poseDetector?.close();
    _poseDetector = null;
    await _poseStreamController.close();
  }
}

/// å§¿æ€æ•°æ®æ‰©å±•
extension PoseExtensions on Pose {
  /// è·å–é¼»å­ä½ç½®ï¼ˆç”¨äºè®¡ç®—çœ¼å±è·ç¦»ï¼‰
  PoseLandmark? get nose {
    return landmarks[PoseLandmarkType.nose];
  }

  /// è·å–å·¦çœ¼
  PoseLandmark? get leftEye {
    return landmarks[PoseLandmarkType.leftEye];
  }

  /// è·å–å³çœ¼
  PoseLandmark? get rightEye {
    return landmarks[PoseLandmarkType.rightEye];
  }

  /// è·å–å·¦è‚©
  PoseLandmark? get leftShoulder {
    return landmarks[PoseLandmarkType.leftShoulder];
  }

  /// è·å–å³è‚©
  PoseLandmark? get rightShoulder {
    return landmarks[PoseLandmarkType.rightShoulder];
  }

  /// è·å–è„ŠæŸ±ä¸­ç‚¹ï¼ˆä¸¤è‚©ä¹‹é—´ï¼‰
  ui.Offset? get spineMidpoint {
    final left = leftShoulder;
    final right = rightShoulder;

    if (left == null || right == null) return null;

    return ui.Offset(
      (left.x + right.x) / 2,
      (left.y + right.y) / 2,
    );
  }

  /// è®¡ç®—è„ŠæŸ±è§’åº¦ï¼ˆ0Â° = ç›´ç«‹ï¼‰
  double? get spineAngle {
    final left = leftShoulder;
    final right = rightShoulder;

    if (left == null || right == null) return null;

    final dx = right.x - left.x;
    final dy = right.y - left.y;

    // è®¡ç®—è§’åº¦ï¼ˆå¼§åº¦è½¬åº¦ï¼‰
    final angle = (math.atan2(dy, dx) * 180 / 3.14159).abs();
    return angle;
  }
}

/// å›¾åƒè½¬æ¢å·¥å…·
class ImageUtils {
  static int _frameCount = 0;

  /// å°† CameraImage è½¬æ¢ä¸º InputImageï¼ˆç”¨äº ML Kitï¼‰
  ///
  /// **å…³é”®ä¿®å¤ï¼š** Android YUV_420_888 (raw=35) å¿…é¡»ä½œä¸º NV21 å¤„ç†
  /// 1. æ‹¼æ¥æ‰€æœ‰ planes çš„å­—èŠ‚
  /// 2. Android å¼ºåˆ¶ä½¿ç”¨ InputImageFormat.nv21
  /// 3. ä½¿ç”¨ fromRawValue åŠ¨æ€è®¡ç®—æ—‹è½¬è§’åº¦
  static InputImage toInputImage(CameraImage image, CameraDescription? cameraDescription) {
    // 1. å¤„ç†å­—èŠ‚æµæ‹¼æ¥ - ç®€å•æ‹¼æ¥æ‰€æœ‰ planes
    final allBytes = WriteBuffer();
    for (final Plane plane in image.planes) {
      allBytes.putUint8List(plane.bytes);
    }
    final bytes = allBytes.done().buffer.asUint8List();

    // 2. è·å–å›¾åƒå°ºå¯¸
    final size = ui.Size(image.width.toDouble(), image.height.toDouble());

    // 3. è®¡ç®—æ—‹è½¬è§’åº¦
    InputImageRotation rotation;

    if (cameraDescription != null) {
      rotation = InputImageRotationValue.fromRawValue(cameraDescription.sensorOrientation)
          ?? InputImageRotation.rotation0deg;

      // è°ƒè¯•æ—¥å¿—ï¼ˆæ¯ 30 å¸§æ‰“å°ä¸€æ¬¡ï¼‰
      _frameCount++;
      if (_frameCount % 30 == 0) {
        debugPrint('ğŸ”„ Camera rotation: sensorOrientation=${cameraDescription.sensorOrientation}Â°, '
            'inputImageRotation=$rotation, '
            'lensDirection=${cameraDescription.lensDirection}');
      }
    } else {
      debugPrint('âš ï¸  No camera description, using default rotation (270deg)');
      rotation = InputImageRotation.rotation270deg;
    }

    // ========== å…³é”®ä¿®å¤ï¼šæ ¼å¼æ˜ å°„ ==========
    // Android YUV_420_888 (raw=35) å¿…é¡»ä½œä¸º NV21 å¤„ç†
    // è¿™æ˜¯ä¿®å¤ InputImageConverterError çš„æ ¸å¿ƒ
    final InputImageFormat format;

    if (Platform.isAndroid) {
      // Android: å¼ºåˆ¶ä½¿ç”¨ nv21ï¼ˆå³ä½¿æºæ ¼å¼æ˜¯ YUV_420_888ï¼‰
      format = InputImageFormat.nv21;
    } else {
      // iOS: å°è¯•ä½¿ç”¨åŸå§‹æ ¼å¼ï¼Œå›é€€åˆ° bgra8888
      format = InputImageFormatValue.fromRawValue(image.format.raw)
          ?? InputImageFormat.bgra8888;
    }

    // 4. æå–è¡Œè·¨åº¦ï¼ˆä½¿ç”¨ Y å¹³é¢ï¼‰
    final bytesPerRow = image.planes.isNotEmpty ? image.planes[0].bytesPerRow : 0;

    // 5. æ„å»ºå…ƒæ•°æ®
    final metadata = InputImageMetadata(
      size: size,
      rotation: rotation,
      format: format,
      bytesPerRow: bytesPerRow,
    );

    // 6. è°ƒè¯•æ—¥å¿—
    if (_frameCount % 30 == 0) {
      debugPrint('ğŸ“· Frame: ${image.width}x${image.height}, '
          'format: raw=${image.format.raw} â†’ $format, '
          'planes: ${image.planes.length}, '
          'bytesPerRow: $bytesPerRow');
    }

    return InputImage.fromBytes(
      bytes: bytes,
      metadata: metadata,
    );
  }
}

